{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "\n",
      "Training model...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def merge_com(data):\n",
    "    data = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        data.loc[i, 'com_len'] = len(data.loc[i, 'comment'])\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'comPos_len'] = len(data.loc[i, 'commentPositive'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comPos_len'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'comNeg_len'] = len(data.loc[i, 'commentNegative'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comNeg_len'] = 0\n",
    "            \n",
    "        data.loc[i, 'nCapital'] = len(re.findall(\"[A-Z]\", data.loc[i, 'comment']))\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalPos'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentPositive']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalPos'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalNeg'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentNegative']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalNeg'] = 0\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentNegative[i]):\n",
    "                data.loc[i, 'hasNegComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.loc[i, 'comment'] + ' ' + data.loc[i, 'commentNegative']\n",
    "            data.loc[i, 'hasNegComment'] = 1\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentPositive[i]):\n",
    "                data.loc[i, 'hasPosComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.comment[i] + ' ' + data.commentPositive[i]\n",
    "            data.loc[i, 'hasPosComment'] = 1\n",
    "        \n",
    "        data.loc[i, 'n_of_exc'] = data.loc[i, 'comment'].count('!')\n",
    "\n",
    "    return data.drop(['commentNegative', 'commentPositive'], axis=1)\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "mystopwords = list(set(stopwords.words('russian')) - set(['много','без','никогда' , 'совсем' , 'не', 'нет', 'более','больше',  'ничего', \"но\", \"хорошо\", \"лучше\"])) + ['это',\"х\",\"р\", \"тыс\", \"тыщ\", \"руб\"] \n",
    "\n",
    "def parse_sentence(sent):\n",
    "    sent = sent.replace('...', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('/', ' ')\n",
    "    exclude = set(punctuation + '0123456789'+u'–—'+u'«»')\n",
    "    merged_text = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "#    tokens = [t_ for t_ in tokens if t_ not in mystopwords]\n",
    "#    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return ' '.join(ch for ch in tokens)\n",
    "\n",
    "\n",
    "print('Preparing dataset\\n')\n",
    "df = pd.read_csv('X_train.csv').drop(['userName', 'property', 'date'], axis=1)\n",
    "df = merge_com(df)\n",
    "df['parsed'] = df.comment.apply(parse_sentence)\n",
    "df = df.drop(['comment'], axis=1)\n",
    "df.reting = df.reting.apply(round)\n",
    "\n",
    "#print('Splitting dataset into train and test\\n')\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df.drop(['reting'], axis=1), \n",
    "#                                                    df['reting'], test_size=0.33)\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1,3)).fit(df['parsed'])\n",
    "\n",
    "tfidf_train = tfidf.transform(df['parsed'])\n",
    "#tfidf_test = tfidf.transform(X_test['parsed'])\n",
    "\n",
    "print('Training model...\\n')\n",
    "clf2 = SVC(C = 1.0, kernel = 'linear').fit(tfidf_train, df['reting'])\n",
    "#print('Score:')\n",
    "#print(clf.score(tfidf_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Preparing dataset\\n')\n",
    "df = pd.read_csv('X_final_test.csv').drop(['userName', 'property', 'date'], axis=1)\n",
    "df = merge_com(df)\n",
    "df['parsed'] = df.comment.apply(parse_sentence)\n",
    "df = df.drop(['comment'], axis=1)\n",
    "#df.reting = df.reting.apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_test = tfidf.transform(df['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['rating'] = clf2.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('X_final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['rating'] = clf2.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Согласна с Сашей и Наташей. Самая лучшая,самая...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хороший пылесос. Вроде качественный. Да, шумно...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пользовалась им почти 2 года, без нареканий. Н...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>До этого у меня был триммер всего с одной наса...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Удобны в использовании. Волосы становятся глад...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ЖКашка достойная внимания.Картинка при сравнен...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Красивая, бежевая, немаркая, ничего лишнего!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>не что не разглаживает, пар то что он выдает о...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Отличный тостер, верой и правдой служит мне уж...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Машинка шила исправно, но после того как я про...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Люди не советую брать такого рода приборы с ци...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Вы что??? может, вы неправильно пользуетесь ка...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Пылесосом не доволен! Проработал с пол года,по...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ноут хороший конечно...но! большинство игр НЕ ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>очень хороший миксер.отлично взбивает белки.и ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>мне понравился</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.06.2016 купил крышку Тефаль для сковороды, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Перепробовал массу наушников ввиду того, что э...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Магнитола неплохая. По поводу настроек звука, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Чистит хорошо, в комплекте 2 штуки с разными ц...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>У меня предыдущая модель этой щетки, лучшего ф...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Прочитала отзывы и купила эти электрощипцы сво...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Попробовал проверить показания датчика и самой...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Покупал панель в июне 2015 г. Масса удобств - ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Выдают 114, проработали месяц, в течение котор...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Электрической щеткой Oral-B пользуюсь уже два ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Нормальный плеер, с включением, конечно, забав...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ужасный компьютер..... за те же деньги можно к...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ну просто замечательная панелька! Первый раз п...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>наконец-то он вышел!!!!!!!!!!!!!!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Всем привет. Аналогичной моделью активно польз...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Купил антену, хотел установить, но не нашёл ст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Телек просто супер!!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>Приобрели его примерно 2 года назад, никаких п...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Купил в М-Видео за 8000р. Пользуюсь пару недел...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>телевизор брал по акции в Ростове за 12990 р. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Ничего, но скорости для записи в реальном режи...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Предохранитель на то и предохранитель, что в с...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>Я не знаю почему никто не может подключить его...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Сегодня установили. Комната 18 кв/м. До темпер...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Чехол отличный! Сидит плотно, как влитой!!! Бе...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>взял пол года назад у брата, брат пользовался ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Быстро, безболезненно, нет вросших волосков, д...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>Забавный случай. Купил дочке, взглянув на рейт...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>Пылик подарили в 2011 году. Для небольшой площ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>ПОльзуюсь наушниками уже год. Отличное качеств...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>Чтобы удалить не нужный канал: 1. Нажать CH LI...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>Zelmer 619.5S Wodnic подойдет только тем, кто ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>Изящный набор с узким аккуратным основанием пр...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>Зубная щетка хорошая, чистит как надо, только ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>За такие деньги ноут просто улет, но ложка дег...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>Соковыжималкой не довольны, просто кошмар, шум...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>Слабые аккумуляторы, проработали 1 год и сдохл...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>после месяца использования телевизора понял, ч...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>Подскажите плиз.Что может быть? Купил наушники...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Купила в подарок пылесос \"Пеликан\" - красивый,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>Игра - улет! Знакомый купил вчера. 1 день игры...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>Дизайн, удачный пиар китайско дешёвки</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>1) Мне Бритва очень нравиться. Читаю недовольн...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>Через месяц весы стали показывать 114 кг..))) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  rating\n",
       "0     Согласна с Сашей и Наташей. Самая лучшая,самая...       5\n",
       "1     Хороший пылесос. Вроде качественный. Да, шумно...       5\n",
       "2     Пользовалась им почти 2 года, без нареканий. Н...       4\n",
       "3     До этого у меня был триммер всего с одной наса...       5\n",
       "4     Удобны в использовании. Волосы становятся глад...       5\n",
       "5     ЖКашка достойная внимания.Картинка при сравнен...       4\n",
       "6          Красивая, бежевая, немаркая, ничего лишнего!       5\n",
       "7     не что не разглаживает, пар то что он выдает о...       1\n",
       "8     Отличный тостер, верой и правдой служит мне уж...       5\n",
       "9     Машинка шила исправно, но после того как я про...       3\n",
       "10    Люди не советую брать такого рода приборы с ци...       1\n",
       "11    Вы что??? может, вы неправильно пользуетесь ка...       5\n",
       "12    Пылесосом не доволен! Проработал с пол года,по...       1\n",
       "13    ноут хороший конечно...но! большинство игр НЕ ...       5\n",
       "14    очень хороший миксер.отлично взбивает белки.и ...       5\n",
       "15                                       мне понравился       5\n",
       "16    16.06.2016 купил крышку Тефаль для сковороды, ...       5\n",
       "17    Перепробовал массу наушников ввиду того, что э...       1\n",
       "18    Магнитола неплохая. По поводу настроек звука, ...       3\n",
       "19    Чистит хорошо, в комплекте 2 штуки с разными ц...       5\n",
       "20    У меня предыдущая модель этой щетки, лучшего ф...       2\n",
       "21    Прочитала отзывы и купила эти электрощипцы сво...       5\n",
       "22    Попробовал проверить показания датчика и самой...       5\n",
       "23    Покупал панель в июне 2015 г. Масса удобств - ...       5\n",
       "24    Выдают 114, проработали месяц, в течение котор...       1\n",
       "25    Электрической щеткой Oral-B пользуюсь уже два ...       5\n",
       "26    Нормальный плеер, с включением, конечно, забав...       4\n",
       "27    Ужасный компьютер..... за те же деньги можно к...       2\n",
       "28    Ну просто замечательная панелька! Первый раз п...       5\n",
       "29                   наконец-то он вышел!!!!!!!!!!!!!!!       5\n",
       "...                                                 ...     ...\n",
       "1124  Всем привет. Аналогичной моделью активно польз...       5\n",
       "1125  Купил антену, хотел установить, но не нашёл ст...       1\n",
       "1126                              Телек просто супер!!!       5\n",
       "1127  Приобрели его примерно 2 года назад, никаких п...       5\n",
       "1128  Купил в М-Видео за 8000р. Пользуюсь пару недел...       4\n",
       "1129  телевизор брал по акции в Ростове за 12990 р. ...       5\n",
       "1130  Ничего, но скорости для записи в реальном режи...       4\n",
       "1131  Предохранитель на то и предохранитель, что в с...       5\n",
       "1132  Я не знаю почему никто не может подключить его...       5\n",
       "1133  Сегодня установили. Комната 18 кв/м. До темпер...       5\n",
       "1134  Чехол отличный! Сидит плотно, как влитой!!! Бе...       5\n",
       "1135  взял пол года назад у брата, брат пользовался ...       4\n",
       "1136  Быстро, безболезненно, нет вросших волосков, д...       5\n",
       "1137  Забавный случай. Купил дочке, взглянув на рейт...       4\n",
       "1138  Пылик подарили в 2011 году. Для небольшой площ...       5\n",
       "1139  ПОльзуюсь наушниками уже год. Отличное качеств...       5\n",
       "1140  Чтобы удалить не нужный канал: 1. Нажать CH LI...       5\n",
       "1141  Zelmer 619.5S Wodnic подойдет только тем, кто ...       1\n",
       "1142  Изящный набор с узким аккуратным основанием пр...       5\n",
       "1143  Зубная щетка хорошая, чистит как надо, только ...       3\n",
       "1144  За такие деньги ноут просто улет, но ложка дег...       5\n",
       "1145  Соковыжималкой не довольны, просто кошмар, шум...       5\n",
       "1146  Слабые аккумуляторы, проработали 1 год и сдохл...       2\n",
       "1147  после месяца использования телевизора понял, ч...       5\n",
       "1148  Подскажите плиз.Что может быть? Купил наушники...       3\n",
       "1149  Купила в подарок пылесос \"Пеликан\" - красивый,...       5\n",
       "1150  Игра - улет! Знакомый купил вчера. 1 день игры...       5\n",
       "1151              Дизайн, удачный пиар китайско дешёвки       1\n",
       "1152  1) Мне Бритва очень нравиться. Читаю недовольн...       5\n",
       "1153  Через месяц весы стали показывать 114 кг..))) ...       1\n",
       "\n",
       "[1154 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.to_csv('X_test_predicted.csv', index = Fal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867068711105\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(tfidf_train, df['reting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893372682364\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(tfidf_train, df['reting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def merge_com(data):\n",
    "    data = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        data.loc[i, 'com_len'] = len(data.loc[i, 'comment'])\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'comPos_len'] = len(data.loc[i, 'commentPositive'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comPos_len'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'comNeg_len'] = len(data.loc[i, 'commentNegative'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comNeg_len'] = 0\n",
    "            \n",
    "        data.loc[i, 'nCapital'] = len(re.findall(\"[A-Z]\", data.loc[i, 'comment']))\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalPos'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentPositive']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalPos'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalNeg'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentNegative']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalNeg'] = 0\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentNegative[i]):\n",
    "                data.loc[i, 'hasNegComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.loc[i, 'comment'] + ' ' + data.loc[i, 'commentNegative']\n",
    "            data.loc[i, 'hasNegComment'] = 1\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentPositive[i]):\n",
    "                data.loc[i, 'hasPosComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.comment[i] + ' ' + data.commentPositive[i]\n",
    "            data.loc[i, 'hasPosComment'] = 1\n",
    "        \n",
    "        data.loc[i, 'n_of_exc'] = data.loc[i, 'comment'].count('!')\n",
    "\n",
    "    return data.drop(['commentNegative', 'commentPositive'], axis=1)\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "mystopwords = list(set(stopwords.words('russian')) - set(['много','без','никогда' , 'совсем' , 'не', 'нет', 'более','больше',  'ничего', \"но\", \"хорошо\", \"лучше\"])) + ['это',\"х\",\"р\", \"тыс\", \"тыщ\", \"руб\"] \n",
    "\n",
    "def parse_sentence(sent):\n",
    "    sent = sent.replace('...', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('/', ' ')\n",
    "    exclude = set(punctuation + '0123456789'+u'–—'+u'«»')\n",
    "    merged_text = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "    #tokens = [t_ for t_ in tokens if t_ not in mystopwords]\n",
    "    #tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return ' '.join(ch for ch in tokens)\n",
    "\n",
    "\n",
    "print('Preparing dataset\\n')\n",
    "df = pd.read_csv('X_train.csv').drop(['userName', 'property', 'date'], axis=1)\n",
    "df = merge_com(df)\n",
    "df['parsed'] = df.comment.apply(parse_sentence)\n",
    "df = df.drop(['comment'], axis=1)\n",
    "df.reting = df.reting.apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data_parsed_not_norm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train and test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Splitting dataset into train and test\\n')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['reting'], axis=1), \n",
    "                                                    df['reting'], test_size=0.33)\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer = 'word', ngram_range=(1,3)).fit(X_train['parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Score:\n",
      "0.659409020218\n"
     ]
    }
   ],
   "source": [
    "tfidf_train = tfidf.transform(X_train['parsed'])\n",
    "tfidf_test = tfidf.transform(X_test['parsed'])\n",
    "\n",
    "print('Training model...\\n')\n",
    "clf = SVC(C = 1.0, kernel = 'linear').fit(tfidf_train, np.array(y_train))\n",
    "print('Score:')\n",
    "print(clf.score(tfidf_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('X_final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>categoryLevel1Id</th>\n",
       "      <th>categoryLevel2Id</th>\n",
       "      <th>brandId</th>\n",
       "      <th>property</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>commentNegative</th>\n",
       "      <th>commentPositive</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003635</td>\n",
       "      <td>406</td>\n",
       "      <td>4060501</td>\n",
       "      <td>62</td>\n",
       "      <td>[{719: 'a9b7ba70783b617e9998dc4dd82eb3c5'}, {1...</td>\n",
       "      <td>e033ded0ac328c61d6b007139ec4e219</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>Согласна с Сашей и Наташей. Самая лучшая,самая...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e0880553-b7f1-4eaa-a800-966133bda683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000782</td>\n",
       "      <td>411</td>\n",
       "      <td>4110104</td>\n",
       "      <td>13</td>\n",
       "      <td>[{34: '9ce895413ebdf6b6dcb69b07dc782591'}, {36...</td>\n",
       "      <td>9f269ce1c8e74e7b1e63f55b856068cd</td>\n",
       "      <td>2010-12-11</td>\n",
       "      <td>Хороший пылесос. Вроде качественный. Да, шумно...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30039f3f-e719-4b47-b588-9a05fd11a799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20021828</td>\n",
       "      <td>413</td>\n",
       "      <td>4130401</td>\n",
       "      <td>63</td>\n",
       "      <td>[{34: 'f982777489055c6563d68c005fd24aad'}, {36...</td>\n",
       "      <td>dc9731cd5ea3ab7e16401cc678d046a5</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>Пользовалась им почти 2 года, без нареканий. Н...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352a5abc-10f4-4668-ae5a-a4285413811a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20027435</td>\n",
       "      <td>413</td>\n",
       "      <td>4130301</td>\n",
       "      <td>678</td>\n",
       "      <td>[{539: '47c7a779688d5f67c55a42811da13210'}, {3...</td>\n",
       "      <td>c9b5ecdf0b853aab02103542187ea208</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>До этого у меня был триммер всего с одной наса...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bfe4564d-944c-4680-b1ce-14e5486ada52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004128</td>\n",
       "      <td>413</td>\n",
       "      <td>4130401</td>\n",
       "      <td>1466</td>\n",
       "      <td>[{162: 'f932bed2d12442d21507b51d22b88dd7'}, {2...</td>\n",
       "      <td>32bf3da6fec001612d3e5048d87c5c64</td>\n",
       "      <td>2009-10-22</td>\n",
       "      <td>Удобны в использовании. Волосы становятся глад...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13547ee0-3400-422f-b831-528caeda9c69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sku  categoryLevel1Id  categoryLevel2Id  brandId  \\\n",
       "0  20003635               406           4060501       62   \n",
       "1  20000782               411           4110104       13   \n",
       "2  20021828               413           4130401       63   \n",
       "3  20027435               413           4130301      678   \n",
       "4  20004128               413           4130401     1466   \n",
       "\n",
       "                                            property  \\\n",
       "0  [{719: 'a9b7ba70783b617e9998dc4dd82eb3c5'}, {1...   \n",
       "1  [{34: '9ce895413ebdf6b6dcb69b07dc782591'}, {36...   \n",
       "2  [{34: 'f982777489055c6563d68c005fd24aad'}, {36...   \n",
       "3  [{539: '47c7a779688d5f67c55a42811da13210'}, {3...   \n",
       "4  [{162: 'f932bed2d12442d21507b51d22b88dd7'}, {2...   \n",
       "\n",
       "                           userName        date  \\\n",
       "0  e033ded0ac328c61d6b007139ec4e219  2012-04-16   \n",
       "1  9f269ce1c8e74e7b1e63f55b856068cd  2010-12-11   \n",
       "2  dc9731cd5ea3ab7e16401cc678d046a5  2012-11-02   \n",
       "3  c9b5ecdf0b853aab02103542187ea208  2016-04-22   \n",
       "4  32bf3da6fec001612d3e5048d87c5c64  2009-10-22   \n",
       "\n",
       "                                             comment commentNegative  \\\n",
       "0  Согласна с Сашей и Наташей. Самая лучшая,самая...             NaN   \n",
       "1  Хороший пылесос. Вроде качественный. Да, шумно...             NaN   \n",
       "2  Пользовалась им почти 2 года, без нареканий. Н...             NaN   \n",
       "3  До этого у меня был триммер всего с одной наса...             NaN   \n",
       "4  Удобны в использовании. Волосы становятся глад...             NaN   \n",
       "\n",
       "  commentPositive                                  uuid  \n",
       "0             NaN  e0880553-b7f1-4eaa-a800-966133bda683  \n",
       "1             NaN  30039f3f-e719-4b47-b588-9a05fd11a799  \n",
       "2             NaN  352a5abc-10f4-4668-ae5a-a4285413811a  \n",
       "3             NaN  bfe4564d-944c-4680-b1ce-14e5486ada52  \n",
       "4             NaN  13547ee0-3400-422f-b831-528caeda9c69  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "0.669129082426\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel = 'linear').fit(tfidf_train, np.array(y_train))\n",
    "print('Score:')\n",
    "print(clf.score(tfidf_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_features = df.columns[6:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['reting'], axis=1), \n",
    "df['reting'], test_size=0.33, random_state=241)\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer = 'word', ngram_range=(1,3)).fit(X_train['parsed'])\n",
    "tfidf_train = tfidf.transform(X_train['parsed'])\n",
    "tfidf_test = tfidf.transform(X_test['parsed'])\n",
    "\n",
    "\n",
    "cont_features_train = X_train[cont_features]\n",
    "cont_features_test = X_test[cont_features]\n",
    "from scipy.sparse import hstack\n",
    "tfidf_data_train = hstack((tfidf_train, cont_features_train)).toarray()\n",
    "tfidf_data_test = hstack((tfidf_test, cont_features_test)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "0.65299377916\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel = 'linear').fit(tfidf_train, np.array(y_train))\n",
    "print('Score:')\n",
    "print(clf.score(tfidf_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
