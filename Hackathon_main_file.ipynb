{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "\n",
      "Splitting dataset into train and test\n",
      "\n",
      "Training model...\n",
      "\n",
      "Score:\n",
      "0.662519440124\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def merge_com(data):\n",
    "    data = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        data.loc[i, 'com_len'] = len(data.loc[i, 'comment'])\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'comPos_len'] = len(data.loc[i, 'commentPositive'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comPos_len'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'comNeg_len'] = len(data.loc[i, 'commentNegative'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comNeg_len'] = 0\n",
    "            \n",
    "        data.loc[i, 'nCapital'] = len(re.findall(\"[A-Z]\", data.loc[i, 'comment']))\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalPos'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentPositive']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalPos'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalNeg'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentNegative']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalNeg'] = 0\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentNegative[i]):\n",
    "                data.loc[i, 'hasNegComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.loc[i, 'comment'] + ' ' + data.loc[i, 'commentNegative']\n",
    "            data.loc[i, 'hasNegComment'] = 1\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentPositive[i]):\n",
    "                data.loc[i, 'hasPosComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.comment[i] + ' ' + data.commentPositive[i]\n",
    "            data.loc[i, 'hasPosComment'] = 1\n",
    "        \n",
    "        data.loc[i, 'n_of_exc'] = data.loc[i, 'comment'].count('!')\n",
    "\n",
    "    return data.drop(['commentNegative', 'commentPositive'], axis=1)\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "mystopwords = list(set(stopwords.words('russian')) - set(['много','без','никогда' , 'совсем' , 'не', 'нет', 'более','больше',  'ничего', \"но\", \"хорошо\", \"лучше\"])) + ['это',\"х\",\"р\", \"тыс\", \"тыщ\", \"руб\"] \n",
    "\n",
    "def parse_sentence(sent):\n",
    "    sent = sent.replace('...', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('/', ' ')\n",
    "    exclude = set(punctuation + '0123456789'+u'–—'+u'«»')\n",
    "    merged_text = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "    tokens = [t_ for t_ in tokens if t_ not in mystopwords]\n",
    "    tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return ' '.join(ch for ch in tokens)\n",
    "\n",
    "\n",
    "print('Preparing dataset\\n')\n",
    "df = pd.read_csv('X_train.csv').drop(['userName', 'property', 'date'], axis=1)\n",
    "df = merge_com(df)\n",
    "df['parsed'] = df.comment.apply(parse_sentence)\n",
    "df = df.drop(['comment'], axis=1)\n",
    "df.reting = df.reting.apply(round)\n",
    "\n",
    "print('Splitting dataset into train and test\\n')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['reting'], axis=1), \n",
    "                                                    df['reting'], test_size=0.33)\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1,3)).fit(X_train['parsed'])\n",
    "\n",
    "tfidf_train = tfidf.transform(X_train['parsed'])\n",
    "tfidf_test = tfidf.transform(X_test['parsed'])\n",
    "\n",
    "print('Training model...\\n')\n",
    "clf = SVC(C = 1.0, kernel = 'linear').fit(tfidf_train, np.array(y_train))\n",
    "print('Score:')\n",
    "print(clf.score(tfidf_test, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def merge_com(data):\n",
    "    data = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        data.loc[i, 'com_len'] = len(data.loc[i, 'comment'])\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'comPos_len'] = len(data.loc[i, 'commentPositive'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comPos_len'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'comNeg_len'] = len(data.loc[i, 'commentNegative'])\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comNeg_len'] = 0\n",
    "            \n",
    "        data.loc[i, 'nCapital'] = len(re.findall(\"[A-Z]\", data.loc[i, 'comment']))\n",
    "        \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalPos'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentPositive']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalPos'] = 0\n",
    "            \n",
    "        try:\n",
    "            data.loc[i, 'nCapitalNeg'] = len(re.findall(\"[A-Z]\", data.loc[i, 'commentNegative']))\n",
    "        except TypeError:\n",
    "            data.loc[i, 'nCapitalNeg'] = 0\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentNegative[i]):\n",
    "                data.loc[i, 'hasNegComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.loc[i, 'comment'] + ' ' + data.loc[i, 'commentNegative']\n",
    "            data.loc[i, 'hasNegComment'] = 1\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(data.commentPositive[i]):\n",
    "                data.loc[i, 'hasPosComment'] = 0\n",
    "        except TypeError:\n",
    "            data.loc[i, 'comment'] = data.comment[i] + ' ' + data.commentPositive[i]\n",
    "            data.loc[i, 'hasPosComment'] = 1\n",
    "        \n",
    "        data.loc[i, 'n_of_exc'] = data.loc[i, 'comment'].count('!')\n",
    "\n",
    "    return data.drop(['commentNegative', 'commentPositive'], axis=1)\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "mystopwords = list(set(stopwords.words('russian')) - set(['много','без','никогда' , 'совсем' , 'не', 'нет', 'более','больше',  'ничего', \"но\", \"хорошо\", \"лучше\"])) + ['это',\"х\",\"р\", \"тыс\", \"тыщ\", \"руб\"] \n",
    "\n",
    "def parse_sentence(sent):\n",
    "    sent = sent.replace('...', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('/', ' ')\n",
    "    exclude = set(punctuation + '0123456789'+u'–—'+u'«»')\n",
    "    merged_text = ''.join(ch for ch in sent if ch not in exclude)\n",
    "    tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "    tokens = [t_ for t_ in tokens if t_ not in mystopwords]\n",
    "    #tokens = [morph.parse(word)[0].normal_form for word in tokens]\n",
    "    return ' '.join(ch for ch in tokens)\n",
    "\n",
    "\n",
    "print('Preparing dataset\\n')\n",
    "df = pd.read_csv('X_train.csv').drop(['userName', 'property', 'date'], axis=1)\n",
    "df = merge_com(df)\n",
    "df['parsed'] = df.comment.apply(parse_sentence)\n",
    "df = df.drop(['comment'], axis=1)\n",
    "df.reting = df.reting.apply(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>categoryLevel1Id</th>\n",
       "      <th>categoryLevel2Id</th>\n",
       "      <th>brandId</th>\n",
       "      <th>reting</th>\n",
       "      <th>com_len</th>\n",
       "      <th>comPos_len</th>\n",
       "      <th>comNeg_len</th>\n",
       "      <th>nCapital</th>\n",
       "      <th>nCapitalPos</th>\n",
       "      <th>nCapitalNeg</th>\n",
       "      <th>hasNegComment</th>\n",
       "      <th>hasPosComment</th>\n",
       "      <th>n_of_exc</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20005023</td>\n",
       "      <td>401</td>\n",
       "      <td>4010201</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>года работала устала лампочка горит больше ничего</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20020647</td>\n",
       "      <td>403</td>\n",
       "      <td>4030101</td>\n",
       "      <td>1425</td>\n",
       "      <td>2</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>месяца истечении гарантийного срока машинка на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20020701</td>\n",
       "      <td>401</td>\n",
       "      <td>4010401</td>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>пользуюсь недели нареканий каких не положитель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30012256</td>\n",
       "      <td>203</td>\n",
       "      <td>2030301</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ребят системный блок подойдёт игры кс го средн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30011341</td>\n",
       "      <td>205</td>\n",
       "      <td>2050201</td>\n",
       "      <td>656</td>\n",
       "      <td>5</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>считаю яри замечательный телефон приятно держа...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sku  categoryLevel1Id  categoryLevel2Id  brandId  reting  com_len  \\\n",
       "0  20005023               401           4010201      826       2     65.0   \n",
       "1  20020647               403           4030101     1425       2   1042.0   \n",
       "2  20020701               401           4010401      124       4    723.0   \n",
       "3  30012256               203           2030301       93       5     71.0   \n",
       "4  30011341               205           2050201      656       5    261.0   \n",
       "\n",
       "   comPos_len  comNeg_len  nCapital  nCapitalPos  nCapitalNeg  hasNegComment  \\\n",
       "0         0.0         0.0       0.0          0.0          0.0            0.0   \n",
       "1         0.0         0.0       0.0          0.0          0.0            0.0   \n",
       "2         0.0         0.0       0.0          0.0          0.0            0.0   \n",
       "3         0.0         0.0       0.0          0.0          0.0            0.0   \n",
       "4         0.0         0.0       0.0          0.0          0.0            0.0   \n",
       "\n",
       "   hasPosComment  n_of_exc                                             parsed  \n",
       "0            0.0       2.0  года работала устала лампочка горит больше ничего  \n",
       "1            0.0       5.0  месяца истечении гарантийного срока машинка на...  \n",
       "2            0.0       0.0  пользуюсь недели нареканий каких не положитель...  \n",
       "3            0.0       0.0  ребят системный блок подойдёт игры кс го средн...  \n",
       "4            0.0      12.0  считаю яри замечательный телефон приятно держа...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"data_parsed_not_norm.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
